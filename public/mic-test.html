<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Microphone Test</title>
  <style>
    body {
      background: #111;
      color: #eee;
      font-family: monospace;
      padding: 20px;
    }
    .log { white-space: pre-wrap; margin-top: 1em; }
    .bar {
      height: 10px;
      background: lime;
      width: 0%;
      transition: width 0.1s;
    }
  </style>
</head>
<body>
  <h2>üé§ Microphone Test</h2>
  <p>This page will attempt to access your microphone.</p>
  <button onclick="startMicTest()">üîä Start Mic Test</button>
  <div class="log" id="log">Idle</div>
  <div class="bar" id="meterBar"></div>

  <script>
    const logEl = document.getElementById('log');
    const meterEl = document.getElementById('meterBar');
    let audioContext, analyser, micStream;

    const logStatus = (...msg) => {
      const line = msg.join(' ');
      console.log(line);
      logEl.innerText += `\n${line}`;
      if (window.ReactNativeWebView) {
        window.ReactNativeWebView.postMessage(JSON.stringify({ type: 'micTestLog', line }));
      }
    };

    async function startMicTest() {
      logEl.innerText = "[Web] STATUS: üîê Requesting microphone access...";
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        micStream = stream;

        const track = stream.getAudioTracks()[0];
        const label = track.label || "(default)";
        logEl.innerText = `[Web] STATUS: ‚úÖ Microphone access granted\nüéµ Track: ${label} (enabled: ${track.enabled})`;

        if (window.ReactNativeWebView) {
          window.ReactNativeWebView.postMessage(JSON.stringify({
            type: 'micTestResult',
            status: 'granted',
            info: [`üéµ Track: ${label} (enabled: ${track.enabled})`]
          }));
        }

        // Web Audio Setup
        audioContext = new (window.AudioContext || window.webkitAudioContext)();
        const micSource = audioContext.createMediaStreamSource(stream);
        analyser = audioContext.createAnalyser();
        analyser.fftSize = 256;
        micSource.connect(analyser);

        const dataArray = new Uint8Array(analyser.frequencyBinCount);

        const animate = () => {
          analyser.getByteFrequencyData(dataArray);
          let avg = dataArray.reduce((a, b) => a + b, 0) / dataArray.length;
          let percent = Math.min(100, (avg / 256) * 100);
          meterEl.style.width = percent + '%';
          requestAnimationFrame(animate);
        };
        animate();

        // Stop stream after 5 seconds
        setTimeout(() => {
          stream.getTracks().forEach(t => t.stop());
          meterEl.style.width = '0%';
          logStatus("[Web] STATUS: üõë Stream stopped");
        }, 5000);

      } catch (err) {
        logStatus("[Web] STATUS: ‚ùå Error accessing mic: " + err.message);
        if (window.ReactNativeWebView) {
          window.ReactNativeWebView.postMessage(JSON.stringify({
            type: 'micTestResult',
            status: 'error',
            error: err.message
          }));
        }
      }
    }
  </script>
</body>
</html>
